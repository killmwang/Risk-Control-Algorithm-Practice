{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4b7765",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# --- 1. å†…å­˜ä¼˜åŒ–å‡½æ•° (è€æœ‹å‹äº†) ---\n",
    "def reduce_mem_usage(df):\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        if col_type != object:\n",
    "            c_min, c_max = df[col].min(), df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "    return df\n",
    "\n",
    "# --- 2. è¯»å–æ•°æ® ---\n",
    "print(\"æ­£åœ¨è¯»å–æ•°æ®...\")\n",
    "train_trans = pd.read_csv('../data/train_transaction.csv')\n",
    "train_id = pd.read_csv('../data/train_identity.csv')\n",
    "train_trans = reduce_mem_usage(train_trans)\n",
    "train_id = reduce_mem_usage(train_id)\n",
    "train = train_trans.merge(train_id, on='TransactionID', how='left')\n",
    "del train_trans, train_id\n",
    "gc.collect()\n",
    "\n",
    "# --- 3. ç‰¹å¾å·¥ç¨‹ (åˆšæ‰åšçš„) ---\n",
    "print(\"æ­£åœ¨æž„é€ ç‰¹å¾...\")\n",
    "# 3.1 æ—¶é—´ç‰¹å¾\n",
    "train['hour'] = (train['TransactionDT'] // 3600) % 24\n",
    "# 3.2 èšåˆç‰¹å¾ (é‡‘é¢åç¦»åº¦)\n",
    "train['card1_amt_mean'] = train.groupby('card1')['TransactionAmt'].transform('mean')\n",
    "train['amt_minus_mean'] = train['TransactionAmt'] - train['card1_amt_mean']\n",
    "# 3.3 é¢‘æ¬¡ç‰¹å¾\n",
    "train['card1_count'] = train.groupby('card1')['TransactionID'].transform('count')\n",
    "\n",
    "print(f\"âœ… æ•°æ®å‡†å¤‡å®Œæ¯•ï¼å½¢çŠ¶: {train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e7ce1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ‰¾å‡ºæ‰€æœ‰æ˜¯å­—ç¬¦ä¸² (object) çš„åˆ—\n",
    "cat_cols = list(train.select_dtypes(include=['object']).columns)\n",
    "\n",
    "print(f\"æ­£åœ¨å°† {len(cat_cols)} ä¸ªæ–‡æœ¬ç‰¹å¾è½¬åŒ–ä¸ºæ•°å­—...\")\n",
    "\n",
    "for col in cat_cols:\n",
    "    # å¡«å……ç©ºå€¼ï¼Œé˜²æ­¢æŠ¥é”™\n",
    "    train[col] = train[col].fillna('unseen_before')\n",
    "    \n",
    "    # è½¬åŒ–\n",
    "    le = LabelEncoder()\n",
    "    train[col] = le.fit_transform(train[col].astype(str))\n",
    "    \n",
    "    # è½¬å®ŒåŽå˜æˆæ•°å­—äº†ï¼Œé¡ºä¾¿æŠŠç±»åž‹è½¬å›ž intï¼Œçœå†…å­˜\n",
    "    train[col] = train[col].astype('int32')\n",
    "\n",
    "print(\"âœ… æ‰€æœ‰ç‰¹å¾å·²æ•°å­—åŒ–ï¼Œå¯ä»¥å–‚ç»™æ¨¡åž‹äº†ï¼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab93c452",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "# 1. å‡†å¤‡è¾“å…¥(X)å’Œè¾“å‡º(y)\n",
    "# åŽ»æŽ‰ 'isFraud' (ç­”æ¡ˆ), 'TransactionID' (æ— æ„ä¹‰ç¼–å·), 'TransactionDT' (æ—¶é—´æˆ³æœ¬èº«)\n",
    "X = train.drop(['isFraud', 'TransactionID', 'TransactionDT'], axis=1)\n",
    "y = train['isFraud']\n",
    "\n",
    "# 2. æŒ‰æ—¶é—´åˆ‡åˆ† (å‰80% vs åŽ20%)\n",
    "split_idx = int(len(X) * 0.8)\n",
    "\n",
    "X_train = X.iloc[:split_idx]\n",
    "y_train = y.iloc[:split_idx]\n",
    "\n",
    "X_val = X.iloc[split_idx:]\n",
    "y_val = y.iloc[split_idx:]\n",
    "\n",
    "print(f\"è®­ç»ƒé›†æ•°é‡: {len(X_train)} (è¿‡åŽ»çš„æ•°æ®)\")\n",
    "print(f\"éªŒè¯é›†æ•°é‡: {len(X_val)} (æœªæ¥çš„æ•°æ® - ç”¨æ¥è€ƒè¯•)\")\n",
    "\n",
    "# 3. æž„å»º LightGBM æ•°æ®é›†å¯¹è±¡\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "val_data = lgb.Dataset(X_val, label=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee52d867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è®¾ç½®å‚æ•° (å·¥ä¸šç•Œæ ‡å‡†èµ·æ‰‹å¼)\n",
    "params = {\n",
    "    'objective': 'binary',      # äºŒåˆ†ç±»ä»»åŠ¡\n",
    "    'metric': 'auc',            # è¯„ä¼°æŒ‡æ ‡ï¼šAUC\n",
    "    'is_unbalance': True,       # å…³é”®ï¼å‘Šè¯‰æ¨¡åž‹åäººå¾ˆå°‘ï¼Œè¦é‡ç‚¹å…³æ³¨\n",
    "    'boosting_type': 'gbdt',    # æ¢¯åº¦æå‡æ ‘\n",
    "    'num_leaves': 31,           # æ ‘çš„å¤æ‚åº¦\n",
    "    'learning_rate': 0.05,      # å­¦ä¹ çŽ‡\n",
    "    'feature_fraction': 0.9,    # æ¯æ¬¡åªç”¨90%çš„ç‰¹å¾ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆ\n",
    "    'bagging_fraction': 0.8,    # æ¯æ¬¡åªç”¨80%çš„æ•°æ®\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': -1\n",
    "}\n",
    "\n",
    "print(\"ðŸš€ å¼€å§‹è®­ç»ƒæ¨¡åž‹...\")\n",
    "\n",
    "clf = lgb.train(\n",
    "    params,\n",
    "    train_data,\n",
    "    num_boost_round=1000,       # æœ€å¤šè·‘1000è½®\n",
    "    valid_sets=[train_data, val_data], \n",
    "    callbacks=[\n",
    "        lgb.early_stopping(stopping_rounds=50), # å¦‚æžœ50è½®æ²¡è¿›æ­¥å°±æå‰åœæ­¢\n",
    "        lgb.log_evaluation(period=50)           # æ¯50è½®æ‰“å°ä¸€æ¬¡åˆ†æ•°\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(f\"ðŸ† æœ€ä½³ AUC åˆ†æ•°: {clf.best_score['valid_1']['auc']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7188327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. ç”»å‡ºç‰¹å¾é‡è¦æ€§æŽ’åº (Feature Importance)\n",
    "# max_num_features=20: åªçœ‹æœ€é‡è¦çš„å‰ 20 ä¸ª\n",
    "lgb.plot_importance(clf, max_num_features=20, figsize=(10, 8), importance_type='split')\n",
    "plt.title('Top 20 Features (Split Importance)')\n",
    "plt.show()\n",
    "\n",
    "# 2. (å¯é€‰) å¦‚æžœä½ æƒ³çœ‹å…·ä½“çš„æ•°å€¼ï¼Œå¯ä»¥æ‰“å°å‡ºæ¥\n",
    "importance = pd.DataFrame({\n",
    "    'feature': clf.feature_name(),\n",
    "    'gain': clf.feature_importance(importance_type='gain')\n",
    "}).sort_values(by='gain', ascending=False)\n",
    "\n",
    "print(importance.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fee3e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_project_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
